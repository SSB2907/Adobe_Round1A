#Challenge 1A: PDF Heading Extraction Tool

## Overview

This project is the official submission for **Challenge 1A** of the Adobe India Hackathon 2025.

The goal is to extract a **structured JSON outline** from a given PDF, including:
- The **title** of the document
- A hierarchical list of headings at levels **H1**, **H2**, and **H3**

The solution is designed to be:
- âš¡ **Fast** â€” Executes under **10 seconds** for a 50-page PDF
- ğŸ“¦ **Offline** â€” Fully Dockerized and requires **no internet access**
- ğŸ’» **Portable** â€” Compatible with **CPU-only (amd64)** architecture
- ğŸŒ **Multilingual** â€” Supports English, Hindi, Marathi, and other Indic languages
- âœ… **Constraint-Compliant** â€” Outputs clean, valid JSON in required format

---

## Project Structure

Challenge_1a/
â”œâ”€â”€ input/
â”‚ â””â”€â”€ sample.pdf
â”œâ”€â”€ output/
â”‚ â””â”€â”€ sample.json
â”œâ”€â”€ extractor.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
---

## Task

Given a PDF file, extract a structured JSON outline with heading hierarchy and metadata.


### Sample Output Format

```json
{
  "title": "A Culinary Journey Through the South of France",
  "outline": [
    {
      "level": "H1",
      "text": "A Culinary Journey Through the South of France",
      "page": 0
    },
    {
      "level": "H1",
      "text": "Introduction",
      "page": 0
    },
    {
      "level": "H1",
      "text": "Types of Food",
      "page": 1
    },
    {
      "level": "H1",
      "text": "Seafood: With its extensive coastline, the South of France oï¬€ers an abundance of fresh",
      "page": 1
    },
    {
      "level": "H1",
      "text": "The cuisine in the South of France is diverse, reflecting the region's rich history and cultural",
      "page": 1
    },
    {
      "level": "H1",
      "text": "Famous Dishes",
      "page": 2
    },
  ]
}
```

How It Works
The script uses PyMuPDF (fitz) for parsing PDFs and applies a rule-based confidence scoring mechanism:
Font size analysis
Boldness detection
Top-of-page placement
Indic script detection (Devanagari, Tamil, etc.)
Span count (multi-line vs single-line detection)
Headings are assigned confidence scores and classified into H1, H2, and H3 levels using dynamic thresholds. A fallback mechanism handles low-information PDFs.


Libraries Used
PyMuPDF (fitz)

re, json, os, time, concurrent.futures

No internet-dependent or heavy ML libraries used


Docker Setup
Build the Docker Image
docker build -t heading-extractor:adobe .

Run the Extractor
Make sure your PDF files are placed inside the input/ directory.
On Linux/macOS/WSL
docker run --rm \
  -v "$(pwd)/input":/app/input \
  -v "$(pwd)/output":/app/output \
  heading-extractor:adobe

On Windows PowerShell
 docker run --rm `
   -v "${PWD}\input:/app/input" `
   -v "${PWD}\output:/app/output" `
    heading-extractor:adobe


Input/Output Format
Input:
Folder: /app/input
Files: One or more .pdf files (â‰¤ 50 pages each)

Output:
Folder: /app/output
File(s): <filename>.json with heading structure

Example
Input: input/Devi_Aarti.pdf
Output:
{
  "title": "à¤¦à¥‡à¤µà¥€à¤šà¥à¤¯à¤¾ à¤†à¤°à¤¤à¥à¤¯à¤¾",
  "outline": [
    { "level": "H1", "text": "à¤¦à¥‡à¤µà¥€à¤šà¥à¤¯à¤¾ à¤†à¤°à¤¤à¥à¤¯à¤¾", "page": 0 },
    { "level": "H3", "text": "à¤¦à¥à¤—à¤¾à¤œ à¤¦à¥‡à¤µà¥€à¤šà¥€ à¤†à¤°à¤¤à¥€", "page": 1 },
    { "level": "H3", "text": "à¤¸à¤‚à¤¤à¥‹à¤·à¥€ à¤®à¤¾à¤¤à¥‡à¤šà¥€ à¤†à¤°à¤¤à¥€", "page": 2 }
  ]
}

Constraints Satisfied
Constraint	Status
Run time â‰¤ 10 sec / 50 pagesâœ…
No internet access	âœ…
Runs on CPU (amd64)	âœ…
Model size â‰¤ 200MB (none used)âœ…
Output JSON format correctâœ…
Multilingual supportâœ…


Notes
Make sure the input/ and output/ directories exist before running the container.